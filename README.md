# シラバススクレイピング&DB登録スクリプト
### ウェブサイトをスクレイピングし、htmlを分析して必要なデータをデータベースに登録するスクリプト群
## DB
- 使用データベース: postgreSQL
- テーブル構成
- - syllabusList
- - - シラバスの情報の中で検索結果として表示する情報のみが格納されている
- - syllabusDetails
- - - 各講義の詳細情報が格納されている
- **正規化が不十分では？**
- - 二つのテーブルで重複している情報があるが、情報を表示する待ち時間が伸びてしまう（誤差レベルであるが…）のでそのままにしている。
- - データ自体が一年に一回更新される更新頻度のものなので、頻繁にデータが書き換わることがない->正規化して保守性が上がることによるコスト低下が有意にならないと判断。
## スクリプトの概要
### scraping.py
- 使用ライブラリ: selenium
- FireFoxを直接操作し、htmlを取得。
- 本来であれば、この段階でDBに登録処理を走らせるのが効率が良いが
DB登録の処理が失敗するとやり直しになるためhtmlのまま指定している
ディレクトリに保存する方式にした。
- サイトに対する負荷を考慮し、ページ遷移を10秒に一回に制限している

### addSyllabusList.py
- 使用ライブラリ: BeautifulSoup4
- 手動で取得した講義リストをDBに登録するスクリプト

### addSyllabusDetail.py
- 使用ライブラリ: BeautifulSoup4
- scraping.pyで取得したhtmlファイルズをDBに登録するスクリプト
- シラバスリストに不足しているデータを挿入する処理も入っている。
- **この詳細情報のhtmlファイルを元に講義リストを作成すれば良いのでは？**
- - 手動で手に入れた講義リストには詳細ページには含まれない情報が含まれているので別々に作成する必要があった。